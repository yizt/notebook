# -*- coding: utf-8 -*-"""   File Name：     keras_batch_size   Description :   测试是否可以在keras 模型不同层使用不同的batch_size   Author :       mick.yi   date：          2019/3/18"""import kerasfrom keras.datasets import cifar10from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambdafrom keras.layers import Conv2D, MaxPooling2Dfrom keras.models import Modelimport numpy as npimport tensorflow as tffrom keras.losses import categorical_crossentropyclass Evaluate(keras.callbacks.Callback):    def __init__(self, eval_fn, X_test, y_test, batch_size):        self.eval_fn = eval_fn        self.X_test = X_test        self.y_test = y_test        self.size = len(X_test)        self.batch_size = batch_size    def on_epoch_end(self, epoch, logs=None):        n, m = self.y_test.shape        y_pred = np.zeros(shape=(2 * n, m))        for i in range(self.size // self.batch_size):            start = i * self.batch_size            end = (i + 1) * self.batch_size            y_pred[2 * start: 2 * end] = self.eval_fn([self.X_test[start: end]])[0]        y_pred = y_pred[::2, :]        y_pred = np.argmax(y_pred, axis=-1)        y_true = np.argmax(self.y_test, axis=-1)        eval_size = self.size // self.batch_size * self.batch_size        print('Current Test accuracy:', np.mean(y_pred[:eval_size] == y_true[:eval_size]))def get_model(batch_size, input_shape, num_classes, stage='train'):    # input_image = Input(batch_shape=(batch_size,) + input_shape, name='input_image')    # input_label = Input(batch_shape=(batch_size, num_classes), name='input_label')    input_image = Input(shape=input_shape, name='input_image')    input_label = Input(shape=(num_classes,), name='input_label')    x = input_image    x = Lambda(        lambda t: tf.reshape(tf.tile(tf.expand_dims(t, axis=1), [1, 2, 1, 1, 1]),                             [-1] + list(input_shape)))(x)    x = Conv2D(32, (3, 3), padding='same')(x)    x = Activation('relu')(x)    x = Conv2D(32, (3, 3))(x)    x = Activation('relu')(x)    x = MaxPooling2D(pool_size=(2, 2))(x)    x = Dropout(0.25)(x)    x = Conv2D(64, (3, 3), padding='same')(x)    x = Activation('relu')(x)    x = Conv2D(64, (3, 3))(x)    x = Activation('relu')(x)    x = MaxPooling2D(pool_size=(2, 2))(x)    x = Dropout(0.25)(x)    x = Flatten()(x)    x = Dense(512)(x)    x = Activation('relu')(x)    x = Dropout(0.5)(x)    x = Dense(num_classes)(x)    x = Activation('softmax')(x)    if stage == 'train':        loss = Lambda(lambda t: my_loss(*t), name='class_loss')([input_label, x])        test_func = keras.backend.function([input_image], [x])        return Model(inputs=[input_image, input_label], outputs=loss), test_func    else:        return Model(inputs=input_image, outputs=x)def generator(X, y, batch_size):    length = X.shape[0]    while True:        indices = np.random.choice(length, batch_size, replace=False)        cur_x = X[indices]        cur_y = y[indices]        yield {"input_image": np.asarray(cur_x), "input_label": np.asarray(cur_y)}, Nonedef my_loss(y_true, y_pred):    y_true = tf.reshape(tf.tile(tf.expand_dims(y_true, axis=1), [1, 2, 1]),                        [-1, 10])    return categorical_crossentropy(y_true, y_pred)def _get_layer(model, name):    for layer in model.layers:        if layer.name == name:            return layer    return Nonedef main():    num_classes = 10    batch_size = 32    (x_train, y_train), (x_test, y_test) = cifar10.load_data()    # Convert class vectors to binary class matrices.    y_train = keras.utils.to_categorical(y_train, num_classes)    y_test = keras.utils.to_categorical(y_test, num_classes)    x_train = x_train.astype('float32')    x_test = x_test.astype('float32')    x_train /= 255    x_test /= 255    # 模型    opt = keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=1e-6)    model, test_func = get_model(batch_size, (32, 32, 3), num_classes)    model.summary()    model._losses = []    model._per_input_losses = {}    for name in ['class_loss']:        layer = _get_layer(model, name)        if layer is None or layer.output in model.losses:            continue        loss = (tf.reduce_mean(layer.output, keepdims=True)                * 1)        model.add_loss(loss)    model.compile(loss=[None],                  optimizer=opt)    # 为每个损失函数增加度量    for name in ['class_loss']:        if name in model.metrics_names:            continue        layer = _get_layer(model, name)        if layer is None:            continue            model.metrics_names.append(name)        loss = (            tf.reduce_mean(layer.output, keepdims=True))        model.metrics_tensors.append(loss)    # 训练    model.fit_generator(generator(x_train, y_train, batch_size=batch_size),                        epochs=20,                        use_multiprocessing=True,                        steps_per_epoch=len(x_train) // batch_size,                        callbacks=[Evaluate(test_func, x_test, y_test, batch_size),                                   keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=3)],                        workers=4)if __name__ == '__main__':    main()